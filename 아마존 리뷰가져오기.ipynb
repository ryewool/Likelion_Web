{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import re\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('/Users/yeonjoo/Desktop/chromedriver_91')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rebel M.</td>\n",
       "      <td>2</td>\n",
       "      <td>January 17, 2019</td>\n",
       "      <td>I am very angry about this product. It adverti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Janice Dysinger</td>\n",
       "      <td>3</td>\n",
       "      <td>December 14, 2018</td>\n",
       "      <td>This is an awesome fat bomb! BUT was surprised...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GG</td>\n",
       "      <td>1</td>\n",
       "      <td>January 13, 2019</td>\n",
       "      <td>No offense to those who gave five stars -- but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joshua jones</td>\n",
       "      <td>1</td>\n",
       "      <td>December 16, 2019</td>\n",
       "      <td>These knocked me right out of ketosis. the fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shopaholic</td>\n",
       "      <td>1</td>\n",
       "      <td>March 17, 2019</td>\n",
       "      <td>These knocked me right about of ketosis. I’ve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>S. M. Baker</td>\n",
       "      <td>1</td>\n",
       "      <td>October 11, 2020</td>\n",
       "      <td>I've bought these before and they've been good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>FloridaChick</td>\n",
       "      <td>5</td>\n",
       "      <td>February 4, 2020</td>\n",
       "      <td>I needed to loose 20lbs quick and Keto is my m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Diva Lilo</td>\n",
       "      <td>5</td>\n",
       "      <td>January 11, 2021</td>\n",
       "      <td>I love that they are individually wrapped. The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Triavalon</td>\n",
       "      <td>2</td>\n",
       "      <td>January 23, 2021</td>\n",
       "      <td>This review is for the strawberry cheesecake m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>aron</td>\n",
       "      <td>5</td>\n",
       "      <td>April 28, 2020</td>\n",
       "      <td>for the people that said it knocked them out o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                user rating               date  \\\n",
       "0           Rebel M.      2   January 17, 2019   \n",
       "1    Janice Dysinger      3  December 14, 2018   \n",
       "2                 GG      1   January 13, 2019   \n",
       "3       Joshua jones      1  December 16, 2019   \n",
       "4        Shopaholic       1     March 17, 2019   \n",
       "..               ...    ...                ...   \n",
       "145      S. M. Baker      1   October 11, 2020   \n",
       "146     FloridaChick      5   February 4, 2020   \n",
       "147        Diva Lilo      5   January 11, 2021   \n",
       "148        Triavalon      2   January 23, 2021   \n",
       "149             aron      5     April 28, 2020   \n",
       "\n",
       "                                                review  \n",
       "0    I am very angry about this product. It adverti...  \n",
       "1    This is an awesome fat bomb! BUT was surprised...  \n",
       "2    No offense to those who gave five stars -- but...  \n",
       "3    These knocked me right out of ketosis. the fir...  \n",
       "4    These knocked me right about of ketosis. I’ve ...  \n",
       "..                                                 ...  \n",
       "145  I've bought these before and they've been good...  \n",
       "146  I needed to loose 20lbs quick and Keto is my m...  \n",
       "147  I love that they are individually wrapped. The...  \n",
       "148  This review is for the strawberry cheesecake m...  \n",
       "149  for the people that said it knocked them out o...  \n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.amazon.com/SlimFast-Snacks-Peanut-Butter-Grams/product-reviews/B07H7NPY5D/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&pageNumber=1'\n",
    "driver.get(url)\n",
    "\n",
    "all_user = []\n",
    "all_ratings = []\n",
    "all_dates = []\n",
    "all_reviews = []\n",
    "\n",
    "for page in range(2,7,1):\n",
    "    time.sleep(3)\n",
    "    page = driver.page_source\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    all_r = soup.find_all(\"div\", class_=\"a-section celwidget\")\n",
    "    \n",
    "    for one in all_r:\n",
    "        \n",
    "        user_one = one.find(\"span\", class_=\"a-profile-name\").text\n",
    "        all_user.append(user_one)  # 사용자 추가\n",
    "        \n",
    "        rating_one = one.find(\"span\", class_=\"a-icon-alt\").text\n",
    "        nums = re.findall(\"\\d+\", rating_one)[0]\n",
    "        all_ratings.append(nums)   # 평점 추가\n",
    "        \n",
    "        # 날짜\n",
    "        date_one = one.find(\"span\", class_=\"a-size-base a-color-secondary review-date\")\n",
    "        texts = date_one.text.split(\"on\")\n",
    "        data = texts[1].strip()\n",
    "        all_dates.append(data)\n",
    "        # 리뷰 추가\n",
    "        review_one = one.find(\"span\",class_=\"a-size-base review-text review-text-content\").text\n",
    "        review = review_one.strip()\n",
    "        all_reviews.append(review)\n",
    "\n",
    "sel_next_page = driver.find_element_by_xpath('//*[@id=\"cm_cr-pagination_bar\"]/ul/li[2]/a')\n",
    "sel_next_page.click()\n",
    "\n",
    "\n",
    "for page in range(2,7,1):\n",
    "    time.sleep(3)\n",
    "    page2 = driver.page_source\n",
    "    soup = BeautifulSoup(page2, 'html.parser')\n",
    "    all_r2 = soup.find_all(\"div\", class_=\"a-section celwidget\")\n",
    "    \n",
    "    for one in all_r2:\n",
    "        \n",
    "        user_one = one.find(\"span\", class_=\"a-profile-name\").text\n",
    "        all_user.append(user_one)  # 사용자 추가\n",
    "        \n",
    "        rating_one = one.find(\"span\", class_=\"a-icon-alt\").text\n",
    "        nums = re.findall(\"\\d+\", rating_one)[0]\n",
    "        all_ratings.append(nums)   # 평점 추가\n",
    "        \n",
    "        # 날짜\n",
    "        date_one = one.find(\"span\", class_=\"a-size-base a-color-secondary review-date\")\n",
    "        texts = date_one.text.split(\"on\")\n",
    "        data = texts[1].strip()\n",
    "        all_dates.append(data)\n",
    "        # 리뷰 추가\n",
    "        review_one = one.find(\"span\",class_=\"a-size-base review-text review-text-content\").text\n",
    "        review = review_one.strip()\n",
    "        all_reviews.append(review)\n",
    "\n",
    "sel_next_page = driver.find_element_by_xpath('//*[@id=\"cm_cr-pagination_bar\"]/ul/li[2]/a')\n",
    "sel_next_page.click()\n",
    "\n",
    "\n",
    "for page in range(2,7,1):\n",
    "    time.sleep(3)\n",
    "    page3 = driver.page_source\n",
    "    soup = BeautifulSoup(page3, 'html.parser')\n",
    "    all_r3 = soup.find_all(\"div\", class_=\"a-section celwidget\")\n",
    "    \n",
    "    for one in all_r3:\n",
    "        \n",
    "        user_one = one.find(\"span\", class_=\"a-profile-name\").text\n",
    "        all_user.append(user_one)  # 사용자 추가\n",
    "        \n",
    "        rating_one = one.find(\"span\", class_=\"a-icon-alt\").text\n",
    "        nums = re.findall(\"\\d+\", rating_one)[0]\n",
    "        all_ratings.append(nums)   # 평점 추가\n",
    "        \n",
    "        # 날짜\n",
    "        date_one = one.find(\"span\", class_=\"a-size-base a-color-secondary review-date\")\n",
    "        texts = date_one.text.split(\"on\")\n",
    "        data = texts[1].strip()\n",
    "        all_dates.append(data)\n",
    "        # 리뷰 추가\n",
    "        review_one = one.find(\"span\",class_=\"a-size-base review-text review-text-content\").text\n",
    "        review = review_one.strip()\n",
    "        all_reviews.append(review)\n",
    "\n",
    "data = {\"user\" : all_user, \"rating\" : all_ratings, \"date\" : all_dates, \"review\" : all_reviews}\n",
    "dat = pd.DataFrame(data)\n",
    "dat.to_csv(\"아맞.csv\", index=False)\n",
    "\n",
    "#print(\"user : \" , all_user2[-1], \"rating :\", all_ratings2[-1])\n",
    "#print(\"review : \", all_reviews2[-1], end=\"\\n\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
